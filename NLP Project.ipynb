{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/Users/sw/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.1\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import string\n",
    "from glob import glob\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sw/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/review_data.csv', sep=',', names=[\"review\",\"rate\",\"emotion\"])\n",
    "new_df = df.dropna()\n",
    "new_df[\"reivew_split\"] = new_df[\"review\"].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = new_df[:32000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rate</th>\n",
       "      <th>emotion</th>\n",
       "      <th>reivew_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>종합 평점 은 4 점 드리다</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[종합, 평점, 은, 4, 점, 드리다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>원작 이 칭송 받다 이유 는 웹툰 계 자체 의 질적 저하 가 심각하다 때문 원작 이...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[원작, 이, 칭송, 받다, 이유, 는, 웹툰, 계, 자체, 의, 질적, 저하, 가...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>나름 의 감동 도 있다 안타깝다 마음 에 가슴 도 먹다 먹다 배우 들 의 연기 가 ...</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[나름, 의, 감동, 도, 있다, 안타깝다, 마음, 에, 가슴, 도, 먹다, 먹다,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>이런 걸 돈 주다 보다 내 자신 이 후회 스럽다 최악 의 쓰레기 영화 김수현 밖 에...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[이런, 걸, 돈, 주다, 보다, 내, 자신, 이, 후회, 스럽다, 최악, 의, 쓰...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>초반 엔 코미디 후반 엔 액션 결론 은 코미디</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>[초반, 엔, 코미디, 후반, 엔, 액션, 결론, 은, 코미디]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>김수현 은 멋있다 일 을 처리 하다 급하다 처리 하다 말고 절차 를 자다 밟다 하다</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[김수현, 은, 멋있다, 일, 을, 처리, 하다, 급하다, 처리, 하다, 말고, 절...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>원작 어디 에 팔 아 먹다</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[원작, 어디, 에, 팔, 아, 먹다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>나름 웃기다 장면 도 있다 지루하다 해도 나름 볼 만 하다</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>[나름, 웃기다, 장면, 도, 있다, 지루하다, 해도, 나름, 볼, 만, 하다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>님 들 이영화 만들다 보다 하다 분들 묶다 두다 클레멘타인 보여주다 야하다</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[님, 들, 이영화, 만들다, 보다, 하다, 분들, 묶다, 두다, 클레멘타인, 보여...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>재밌다 좀 억 지 감동 짜내다 좀 유치하다</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>[재밌다, 좀, 억, 지, 감동, 짜내다, 좀, 유치하다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>이 게 어떻다 흥행 하다 궁금하다</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[이, 게, 어떻다, 흥행, 하다, 궁금하다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>내용 이 정말 감동 적다</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>[내용, 이, 정말, 감동, 적다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>어떻다 영화 든 간 에 10 대다 여자애 들 이 가장 좋아하다 영화 이면 망 작 임</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>[어떻다, 영화, 든, 간, 에, 10, 대다, 여자애, 들, 이, 가장, 좋아하다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>김수현 연기 굿</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[김수현, 연기, 굿]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>만화 랑 무엇 인가 많이 다르다</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>[만화, 랑, 무엇, 인가, 많이, 다르다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>완벽하다 노잼 칠 광 구 급</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[완벽하다, 노잼, 칠, 광, 구, 급]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>연기력 에는 논 하고 싶다 않다 흥미 있다 소재 를 자다 마무리 못 지다 생각 이든...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>[연기력, 에는, 논, 하고, 싶다, 않다, 흥미, 있다, 소재, 를, 자다, 마무...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>진심 노잼 친구 한테 끌리다 가다 돈 아깝다 죽다 하품 만 계속 나오다</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>[진심, 노잼, 친구, 한테, 끌리다, 가다, 돈, 아깝다, 죽다, 하품, 만, 계...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>김수현 이라는 히든카드 가 있다 이영화 가 그나마 살아나다 것 같다</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[김수현, 이라는, 히든카드, 가, 있다, 이영화, 가, 그나마, 살아나다, 것, 같다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>중수 현도 비호감 각본 도 비호감 감독 도 비호감 모든 게 비호감</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[중수, 현도, 비호감, 각본, 도, 비호감, 감독, 도, 비호감, 모든, 게, 비호감]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>나쁘다 좋다 않다 그냥 그런 영화 웹툰 내용 을 생략 하다 다해 도 1 점 은 너무...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>[나쁘다, 좋다, 않다, 그냥, 그런, 영화, 웹툰, 내용, 을, 생략, 하다, 다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>빨갱이 간첩 미화 영화</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[빨갱이, 간첩, 미화, 영화]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>왜 충무로 표 는 마무리 를 항상 질질 끌 고 눈물 을 자극 하고 싶다 걸다 진짜 ...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>[왜, 충무로, 표, 는, 마무리, 를, 항상, 질질, 끌, 고, 눈물, 을, 자극...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>동네 바보 형 들 을 조심 하라 그 들 은 인간 병기 일지 모르다</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[동네, 바보, 형, 들, 을, 조심, 하라, 그, 들, 은, 인간, 병기, 일지,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>댓 들 이 다 왜 이르다 지금 까지 웹툰 영화 화 되어다 작품 중 에 정말 성 곡 ...</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[댓, 들, 이, 다, 왜, 이르다, 지금, 까지, 웹툰, 영화, 화, 되어다, 작...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>만화 도 쓰레긴데 영화 가 좋다 리가 영화관 에서 돈 이 끄다 워 서 울 뻔</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[만화, 도, 쓰레긴데, 영화, 가, 좋다, 리가, 영화관, 에서, 돈, 이, 끄다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>이 거 영화로 보 니까 존나 오그 라 듬</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[이, 거, 영화로, 보, 니까, 존나, 오그, 라, 듬]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>영화 시간 늘리다 서다 웹툰 에 괜찮다 내용 더 넣다 그렇다</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>[영화, 시간, 늘리다, 서다, 웹툰, 에, 괜찮다, 내용, 더, 넣다, 그렇다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>노잼 핵 노잼 원폭 노잼 원작 하고 너무 다르다</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[노잼, 핵, 노잼, 원폭, 노잼, 원작, 하고, 너무, 다르다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>잘생기다 배우 몇 명 만 캐스팅 하다 관객수 가 600만 넘다 수 있다</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[잘생기다, 배우, 몇, 명, 만, 캐스팅, 하다, 관객수, 가, 600만, 넘다,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32082</th>\n",
       "      <td>재밌다</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[재밌다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32083</th>\n",
       "      <td>구해 서 보기 가 힘들다 안타깝다 지금 보다 뒤 떨어지다 않다 영상 과 스토리 가 ...</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[구해, 서, 보기, 가, 힘들다, 안타깝다, 지금, 보다, 뒤, 떨어지다, 않다,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32084</th>\n",
       "      <td>가슴 이 싸하다 쓸다 내리다 안타 크다 슬프다 사랑 이야기</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[가슴, 이, 싸하다, 쓸다, 내리다, 안타, 크다, 슬프다, 사랑, 이야기]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32085</th>\n",
       "      <td>서 사극 에 딱 이정 도 규모 스토리 음악 애절하다 균형 자다 맞춤</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>[서, 사극, 에, 딱, 이정, 도, 규모, 스토리, 음악, 애절하다, 균형, 자다...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32086</th>\n",
       "      <td>여기 에 양조위 가 왜 나오다 미치다 게이버 야</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[여기, 에, 양조위, 가, 왜, 나오다, 미치다, 게이버, 야]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32087</th>\n",
       "      <td>사랑 을 선택 하다 기회 조차 갖다 못 하다 청춘 들</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>[사랑, 을, 선택, 하다, 기회, 조차, 갖다, 못, 하다, 청춘, 들]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32088</th>\n",
       "      <td>너무 안타깝다 그 들</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>[너무, 안타깝다, 그, 들]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32089</th>\n",
       "      <td>언제 다시 오다 내 사랑 그리움 에 숨 이 막히다 가슴 이 아리다</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>[언제, 다시, 오다, 내, 사랑, 그리움, 에, 숨, 이, 막히다, 가슴, 이, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32090</th>\n",
       "      <td>가슴 이 시리다 눈물 나 는 사랑 매염방 혼신 의 연기</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[가슴, 이, 시리다, 눈물, 나, 는, 사랑, 매염방, 혼신, 의, 연기]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32091</th>\n",
       "      <td>가슴 한편 이 시리다 파랗다 물들다 안녕 내 사랑 이여</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>[가슴, 한편, 이, 시리다, 파랗다, 물들다, 안녕, 내, 사랑, 이여]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32092</th>\n",
       "      <td>10년 지나다 잊혀지다 않다 영화 공중전화 키스신 도 너무 멋지다</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>[10년, 지나다, 잊혀지다, 않다, 영화, 공중전화, 키스신, 도, 너무, 멋지다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32093</th>\n",
       "      <td>여운 이 남다 영 화란 이런 것 이다 지워지다 않다 그 들 의 사랑</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[여운, 이, 남다, 영, 화란, 이런, 것, 이다, 지워지다, 않다, 그, 들, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32094</th>\n",
       "      <td>매염방 이 다시 보고 싶다</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>[매염방, 이, 다시, 보고, 싶다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32095</th>\n",
       "      <td>크다 뜻 을 위해 서 그 들 은 희생 하다</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[크다, 뜻, 을, 위해, 서, 그, 들, 은, 희생, 하다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32096</th>\n",
       "      <td>님 은 언제 다시 오다 한숨 이 푹푹 묻다 나다</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[님, 은, 언제, 다시, 오다, 한숨, 이, 푹푹, 묻다, 나다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32097</th>\n",
       "      <td>지나치다 부리다 멋 이 흠</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[지나치다, 부리다, 멋, 이, 흠]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32098</th>\n",
       "      <td>액션 이 화려하다 않다 현실 적 이며 살짝 웃기 고 볼 만 하다 생각 하다 시간 도...</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>[액션, 이, 화려하다, 않다, 현실, 적, 이며, 살짝, 웃기, 고, 볼, 만, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32099</th>\n",
       "      <td>보지 말다 진짜 별로 임</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[보지, 말다, 진짜, 별로, 임]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32100</th>\n",
       "      <td>명작 이네 굿굿굿</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[명작, 이네, 굿굿굿]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32101</th>\n",
       "      <td>재미 도 스토리 도 그 저 그런 영화</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>[재미, 도, 스토리, 도, 그, 저, 그런, 영화]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32102</th>\n",
       "      <td>강원도 심포니 졸작 과 수작 의 줄타기 욕 하다 하다 뭐 가 하나 나오다 칭찬 하다...</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>[강원도, 심포니, 졸작, 과, 수작, 의, 줄타기, 욕, 하다, 하다, 뭐, 가,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32103</th>\n",
       "      <td>수 많다 기 억 속 의 편린 하나 가 인생 의 향방 을 좌우 하다 하다</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>[수, 많다, 기, 억, 속, 의, 편린, 하나, 가, 인생, 의, 향방, 을, 좌...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32104</th>\n",
       "      <td>어디서 많이 본 듯 한 사람 이 있다 매니 파키 아 오가다 주인공</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>[어디서, 많이, 본, 듯, 한, 사람, 이, 있다, 매니, 파키, 아, 오가다, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32105</th>\n",
       "      <td>장르 가 코믹 이다 보다 검색 후 에 알다</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>[장르, 가, 코믹, 이다, 보다, 검색, 후, 에, 알다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32106</th>\n",
       "      <td>이 것 은 조폭 영화 가 아니다 보다 많다 생각 을 하다 되다 저 예산 영화 임 에...</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[이, 것, 은, 조폭, 영화, 가, 아니다, 보다, 많다, 생각, 을, 하다, 되...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32107</th>\n",
       "      <td>재다 정말 결망 도 좋다</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[재다, 정말, 결망, 도, 좋다]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32108</th>\n",
       "      <td>영화 라기 보다 동네형 들 이야기 를 듣다 평이하다 약간 지루함 은 있다 글쎄요 2...</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>[영화, 라기, 보다, 동네형, 들, 이야기, 를, 듣다, 평이하다, 약간, 지루함...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32109</th>\n",
       "      <td>뭔가 되게 담백하다 소소하다 긴장감 몰입도 는 깊다 영화</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>[뭔가, 되게, 담백하다, 소소하다, 긴장감, 몰입도, 는, 깊다, 영화]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32110</th>\n",
       "      <td>나이 먹다 아저씨 들 이 일찐 놀이 하다 영화 개 역겹다 알바 풀다 현 실감 개 진...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[나이, 먹다, 아저씨, 들, 이, 일찐, 놀이, 하다, 영화, 개, 역겹다, 알바...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32111</th>\n",
       "      <td>뭐 그럭저럭 볼 만하 네 함 보쇼</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>[뭐, 그럭저럭, 볼, 만하, 네, 함, 보쇼]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  rate  emotion  \\\n",
       "0                                        종합 평점 은 4 점 드리다     4        1   \n",
       "1      원작 이 칭송 받다 이유 는 웹툰 계 자체 의 질적 저하 가 심각하다 때문 원작 이...     1        0   \n",
       "2      나름 의 감동 도 있다 안타깝다 마음 에 가슴 도 먹다 먹다 배우 들 의 연기 가 ...    10        2   \n",
       "3      이런 걸 돈 주다 보다 내 자신 이 후회 스럽다 최악 의 쓰레기 영화 김수현 밖 에...     1        0   \n",
       "4                              초반 엔 코미디 후반 엔 액션 결론 은 코미디     7        2   \n",
       "5         김수현 은 멋있다 일 을 처리 하다 급하다 처리 하다 말고 절차 를 자다 밟다 하다     5        1   \n",
       "6                                         원작 어디 에 팔 아 먹다     1        0   \n",
       "7                       나름 웃기다 장면 도 있다 지루하다 해도 나름 볼 만 하다     6        1   \n",
       "8              님 들 이영화 만들다 보다 하다 분들 묶다 두다 클레멘타인 보여주다 야하다     1        0   \n",
       "9                                재밌다 좀 억 지 감동 짜내다 좀 유치하다     7        2   \n",
       "10                                    이 게 어떻다 흥행 하다 궁금하다     1        0   \n",
       "11                                         내용 이 정말 감동 적다     9        2   \n",
       "12        어떻다 영화 든 간 에 10 대다 여자애 들 이 가장 좋아하다 영화 이면 망 작 임     6        1   \n",
       "13                                              김수현 연기 굿    10        2   \n",
       "14                                     만화 랑 무엇 인가 많이 다르다     6        1   \n",
       "15                                       완벽하다 노잼 칠 광 구 급     1        0   \n",
       "16     연기력 에는 논 하고 싶다 않다 흥미 있다 소재 를 자다 마무리 못 지다 생각 이든...     7        2   \n",
       "17               진심 노잼 친구 한테 끌리다 가다 돈 아깝다 죽다 하품 만 계속 나오다     3        0   \n",
       "18                 김수현 이라는 히든카드 가 있다 이영화 가 그나마 살아나다 것 같다     5        1   \n",
       "19                  중수 현도 비호감 각본 도 비호감 감독 도 비호감 모든 게 비호감     1        0   \n",
       "20     나쁘다 좋다 않다 그냥 그런 영화 웹툰 내용 을 생략 하다 다해 도 1 점 은 너무...     7        2   \n",
       "21                                          빨갱이 간첩 미화 영화     1        0   \n",
       "22     왜 충무로 표 는 마무리 를 항상 질질 끌 고 눈물 을 자극 하고 싶다 걸다 진짜 ...     6        1   \n",
       "23                  동네 바보 형 들 을 조심 하라 그 들 은 인간 병기 일지 모르다     5        1   \n",
       "24     댓 들 이 다 왜 이르다 지금 까지 웹툰 영화 화 되어다 작품 중 에 정말 성 곡 ...    10        2   \n",
       "25            만화 도 쓰레긴데 영화 가 좋다 리가 영화관 에서 돈 이 끄다 워 서 울 뻔     1        0   \n",
       "26                                이 거 영화로 보 니까 존나 오그 라 듬     2        0   \n",
       "27                     영화 시간 늘리다 서다 웹툰 에 괜찮다 내용 더 넣다 그렇다     2        0   \n",
       "28                            노잼 핵 노잼 원폭 노잼 원작 하고 너무 다르다     1        0   \n",
       "29               잘생기다 배우 몇 명 만 캐스팅 하다 관객수 가 600만 넘다 수 있다     1        0   \n",
       "...                                                  ...   ...      ...   \n",
       "32082                                                재밌다    10        2   \n",
       "32083  구해 서 보기 가 힘들다 안타깝다 지금 보다 뒤 떨어지다 않다 영상 과 스토리 가 ...    10        2   \n",
       "32084                   가슴 이 싸하다 쓸다 내리다 안타 크다 슬프다 사랑 이야기    10        2   \n",
       "32085              서 사극 에 딱 이정 도 규모 스토리 음악 애절하다 균형 자다 맞춤     8        2   \n",
       "32086                         여기 에 양조위 가 왜 나오다 미치다 게이버 야    10        2   \n",
       "32087                      사랑 을 선택 하다 기회 조차 갖다 못 하다 청춘 들     9        2   \n",
       "32088                                        너무 안타깝다 그 들     9        2   \n",
       "32089               언제 다시 오다 내 사랑 그리움 에 숨 이 막히다 가슴 이 아리다     9        2   \n",
       "32090                     가슴 이 시리다 눈물 나 는 사랑 매염방 혼신 의 연기    10        2   \n",
       "32091                     가슴 한편 이 시리다 파랗다 물들다 안녕 내 사랑 이여     9        2   \n",
       "32092               10년 지나다 잊혀지다 않다 영화 공중전화 키스신 도 너무 멋지다     9        2   \n",
       "32093              여운 이 남다 영 화란 이런 것 이다 지워지다 않다 그 들 의 사랑    10        2   \n",
       "32094                                     매염방 이 다시 보고 싶다     9        2   \n",
       "32095                            크다 뜻 을 위해 서 그 들 은 희생 하다    10        2   \n",
       "32096                         님 은 언제 다시 오다 한숨 이 푹푹 묻다 나다    10        2   \n",
       "32097                                     지나치다 부리다 멋 이 흠     5        1   \n",
       "32098  액션 이 화려하다 않다 현실 적 이며 살짝 웃기 고 볼 만 하다 생각 하다 시간 도...     9        2   \n",
       "32099                                      보지 말다 진짜 별로 임     1        0   \n",
       "32100                                          명작 이네 굿굿굿    10        2   \n",
       "32101                               재미 도 스토리 도 그 저 그런 영화     4        1   \n",
       "32102  강원도 심포니 졸작 과 수작 의 줄타기 욕 하다 하다 뭐 가 하나 나오다 칭찬 하다...     7        2   \n",
       "32103            수 많다 기 억 속 의 편린 하나 가 인생 의 향방 을 좌우 하다 하다     8        2   \n",
       "32104               어디서 많이 본 듯 한 사람 이 있다 매니 파키 아 오가다 주인공     5        1   \n",
       "32105                            장르 가 코믹 이다 보다 검색 후 에 알다     6        1   \n",
       "32106  이 것 은 조폭 영화 가 아니다 보다 많다 생각 을 하다 되다 저 예산 영화 임 에...    10        2   \n",
       "32107                                      재다 정말 결망 도 좋다    10        2   \n",
       "32108  영화 라기 보다 동네형 들 이야기 를 듣다 평이하다 약간 지루함 은 있다 글쎄요 2...     6        1   \n",
       "32109                    뭔가 되게 담백하다 소소하다 긴장감 몰입도 는 깊다 영화    10        2   \n",
       "32110  나이 먹다 아저씨 들 이 일찐 놀이 하다 영화 개 역겹다 알바 풀다 현 실감 개 진...     1        0   \n",
       "32111                                 뭐 그럭저럭 볼 만하 네 함 보쇼     9        2   \n",
       "\n",
       "                                            reivew_split  \n",
       "0                                 [종합, 평점, 은, 4, 점, 드리다]  \n",
       "1      [원작, 이, 칭송, 받다, 이유, 는, 웹툰, 계, 자체, 의, 질적, 저하, 가...  \n",
       "2      [나름, 의, 감동, 도, 있다, 안타깝다, 마음, 에, 가슴, 도, 먹다, 먹다,...  \n",
       "3      [이런, 걸, 돈, 주다, 보다, 내, 자신, 이, 후회, 스럽다, 최악, 의, 쓰...  \n",
       "4                    [초반, 엔, 코미디, 후반, 엔, 액션, 결론, 은, 코미디]  \n",
       "5      [김수현, 은, 멋있다, 일, 을, 처리, 하다, 급하다, 처리, 하다, 말고, 절...  \n",
       "6                                  [원작, 어디, 에, 팔, 아, 먹다]  \n",
       "7           [나름, 웃기다, 장면, 도, 있다, 지루하다, 해도, 나름, 볼, 만, 하다]  \n",
       "8      [님, 들, 이영화, 만들다, 보다, 하다, 분들, 묶다, 두다, 클레멘타인, 보여...  \n",
       "9                       [재밌다, 좀, 억, 지, 감동, 짜내다, 좀, 유치하다]  \n",
       "10                             [이, 게, 어떻다, 흥행, 하다, 궁금하다]  \n",
       "11                                   [내용, 이, 정말, 감동, 적다]  \n",
       "12     [어떻다, 영화, 든, 간, 에, 10, 대다, 여자애, 들, 이, 가장, 좋아하다...  \n",
       "13                                          [김수현, 연기, 굿]  \n",
       "14                              [만화, 랑, 무엇, 인가, 많이, 다르다]  \n",
       "15                                [완벽하다, 노잼, 칠, 광, 구, 급]  \n",
       "16     [연기력, 에는, 논, 하고, 싶다, 않다, 흥미, 있다, 소재, 를, 자다, 마무...  \n",
       "17     [진심, 노잼, 친구, 한테, 끌리다, 가다, 돈, 아깝다, 죽다, 하품, 만, 계...  \n",
       "18     [김수현, 이라는, 히든카드, 가, 있다, 이영화, 가, 그나마, 살아나다, 것, 같다]  \n",
       "19     [중수, 현도, 비호감, 각본, 도, 비호감, 감독, 도, 비호감, 모든, 게, 비호감]  \n",
       "20     [나쁘다, 좋다, 않다, 그냥, 그런, 영화, 웹툰, 내용, 을, 생략, 하다, 다...  \n",
       "21                                     [빨갱이, 간첩, 미화, 영화]  \n",
       "22     [왜, 충무로, 표, 는, 마무리, 를, 항상, 질질, 끌, 고, 눈물, 을, 자극...  \n",
       "23     [동네, 바보, 형, 들, 을, 조심, 하라, 그, 들, 은, 인간, 병기, 일지,...  \n",
       "24     [댓, 들, 이, 다, 왜, 이르다, 지금, 까지, 웹툰, 영화, 화, 되어다, 작...  \n",
       "25     [만화, 도, 쓰레긴데, 영화, 가, 좋다, 리가, 영화관, 에서, 돈, 이, 끄다...  \n",
       "26                      [이, 거, 영화로, 보, 니까, 존나, 오그, 라, 듬]  \n",
       "27         [영화, 시간, 늘리다, 서다, 웹툰, 에, 괜찮다, 내용, 더, 넣다, 그렇다]  \n",
       "28                  [노잼, 핵, 노잼, 원폭, 노잼, 원작, 하고, 너무, 다르다]  \n",
       "29     [잘생기다, 배우, 몇, 명, 만, 캐스팅, 하다, 관객수, 가, 600만, 넘다,...  \n",
       "...                                                  ...  \n",
       "32082                                              [재밌다]  \n",
       "32083  [구해, 서, 보기, 가, 힘들다, 안타깝다, 지금, 보다, 뒤, 떨어지다, 않다,...  \n",
       "32084        [가슴, 이, 싸하다, 쓸다, 내리다, 안타, 크다, 슬프다, 사랑, 이야기]  \n",
       "32085  [서, 사극, 에, 딱, 이정, 도, 규모, 스토리, 음악, 애절하다, 균형, 자다...  \n",
       "32086               [여기, 에, 양조위, 가, 왜, 나오다, 미치다, 게이버, 야]  \n",
       "32087          [사랑, 을, 선택, 하다, 기회, 조차, 갖다, 못, 하다, 청춘, 들]  \n",
       "32088                                   [너무, 안타깝다, 그, 들]  \n",
       "32089  [언제, 다시, 오다, 내, 사랑, 그리움, 에, 숨, 이, 막히다, 가슴, 이, ...  \n",
       "32090         [가슴, 이, 시리다, 눈물, 나, 는, 사랑, 매염방, 혼신, 의, 연기]  \n",
       "32091          [가슴, 한편, 이, 시리다, 파랗다, 물들다, 안녕, 내, 사랑, 이여]  \n",
       "32092    [10년, 지나다, 잊혀지다, 않다, 영화, 공중전화, 키스신, 도, 너무, 멋지다]  \n",
       "32093  [여운, 이, 남다, 영, 화란, 이런, 것, 이다, 지워지다, 않다, 그, 들, ...  \n",
       "32094                               [매염방, 이, 다시, 보고, 싶다]  \n",
       "32095                 [크다, 뜻, 을, 위해, 서, 그, 들, 은, 희생, 하다]  \n",
       "32096              [님, 은, 언제, 다시, 오다, 한숨, 이, 푹푹, 묻다, 나다]  \n",
       "32097                               [지나치다, 부리다, 멋, 이, 흠]  \n",
       "32098  [액션, 이, 화려하다, 않다, 현실, 적, 이며, 살짝, 웃기, 고, 볼, 만, ...  \n",
       "32099                                [보지, 말다, 진짜, 별로, 임]  \n",
       "32100                                      [명작, 이네, 굿굿굿]  \n",
       "32101                      [재미, 도, 스토리, 도, 그, 저, 그런, 영화]  \n",
       "32102  [강원도, 심포니, 졸작, 과, 수작, 의, 줄타기, 욕, 하다, 하다, 뭐, 가,...  \n",
       "32103  [수, 많다, 기, 억, 속, 의, 편린, 하나, 가, 인생, 의, 향방, 을, 좌...  \n",
       "32104  [어디서, 많이, 본, 듯, 한, 사람, 이, 있다, 매니, 파키, 아, 오가다, ...  \n",
       "32105                  [장르, 가, 코믹, 이다, 보다, 검색, 후, 에, 알다]  \n",
       "32106  [이, 것, 은, 조폭, 영화, 가, 아니다, 보다, 많다, 생각, 을, 하다, 되...  \n",
       "32107                                [재다, 정말, 결망, 도, 좋다]  \n",
       "32108  [영화, 라기, 보다, 동네형, 들, 이야기, 를, 듣다, 평이하다, 약간, 지루함...  \n",
       "32109          [뭔가, 되게, 담백하다, 소소하다, 긴장감, 몰입도, 는, 깊다, 영화]  \n",
       "32110  [나이, 먹다, 아저씨, 들, 이, 일찐, 놀이, 하다, 영화, 개, 역겹다, 알바...  \n",
       "32111                         [뭐, 그럭저럭, 볼, 만하, 네, 함, 보쇼]  \n",
       "\n",
       "[32000 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_class = [\n",
    "    \"POSI\" if new_df.iloc[i]['rate'] >= 8\n",
    "    else\n",
    "    \"SOSO\" if new_df.iloc[i]['rate'] >= 4\n",
    "    else\n",
    "    \"NEGA\"\n",
    "    for i in range(new_df.shape[0])\n",
    "]\n",
    "new_df[\"class\"] = emotion_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 10000\n",
    "tokenizer = Tokenizer(num_words=num_words)\n",
    "tokenizer.fit_on_texts(new_df[\"review\"])\n",
    "\n",
    "if num_words is None:\n",
    "    num_words = len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0, 1826,   56,    9,  304,   37,\n",
       "        585], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_tokens = tokenizer.texts_to_sequences(new_df[\"review\"])\n",
    "\n",
    "x_tokens[0]\n",
    "\n",
    "num_tokens = [len(tokens) for tokens in x_tokens]\n",
    "num_tokens = np.array(num_tokens)\n",
    "\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "max_tokens = int(max_tokens)\n",
    "max_tokens\n",
    "\n",
    "np.sum(num_tokens < max_tokens) / len(num_tokens)\n",
    "\n",
    "pad = 'pre'\n",
    "\n",
    "x_tokens_pad = pad_sequences(x_tokens, maxlen=max_tokens,\n",
    "                            padding=pad, truncating=pad)\n",
    "\n",
    "x_tokens_pad.shape\n",
    "\n",
    "x_tokens_pad[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_np = x_tokens_pad[:int(len(new_df)*0.8)]\n",
    "X_train_np = x_tokens_pad[int(len(new_df)*0.8):]\n",
    "\n",
    "n_values = np.max(new_df[\"emotion\"]) + 1\n",
    "y = np.eye(n_values)[new_df[\"emotion\"]]\n",
    "\n",
    "y_test_np = y[:int(len(new_df)*0.8)]\n",
    "y_train_np = y[int(len(new_df)*0.8):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models.doc2vec import Doc2Vec\n",
    "# from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = new_df[:int(len(new_df)*0.8)]\n",
    "# test_df = new_df[int(len(new_df)*0.8):]\n",
    "\n",
    "# TaggedDocument = namedtuple('TaggedDocument', 'words tags')\n",
    "# tagged_train_docs = [TaggedDocument(d, c) for d, c in train_df[['reivew_split', 'class']].values]\n",
    "# tagged_test_docs = [TaggedDocument(d, c) for d, c in test_df[['reivew_split', 'class']].values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import multiprocessing\n",
    "# cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_vectorizer = Doc2Vec(\n",
    "#     dm=0,            # PV-DBOW / default 1\n",
    "#     dbow_words=1,    # w2v simultaneous with DBOW d2v / default 0\n",
    "#     window=8,        # distance between the predicted word and context words\n",
    "#     size=300,        # vector size\n",
    "#     alpha=0.025,     # learning-rate\n",
    "#     seed=1234,\n",
    "#     min_count=20,    # ignore with freq lower\n",
    "#     min_alpha=0.025, # min learning-rate\n",
    "#     workers=cores,   # multi cpu\n",
    "#     hs = 1,          # hierarchical softmax / default 0\n",
    "#     negative = 10,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_vectorizer.build_vocab(tagged_train_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doc_vectorizer.corpus_count\n",
    "# doc_vectorizer.iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(10):\n",
    "#     doc_vectorizer.train(tagged_train_docs, total_examples=doc_vectorizer.corpus_count, epochs=doc_vectorizer.iter)\n",
    "#     doc_vectorizer.alpha -= 0.002 # decrease the learning rate\n",
    "#     doc_vectorizer.min_alpha = doc_vectorizer.alpha # fix the learning rate, no decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'Doc2vec(dbow+w,d300,n10,hs,w8,mc20,s0.001,t24).model'\n",
    "# doc_vectorizer.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "# doc_vectorizer = Doc2Vec.load(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = [doc_vectorizer.infer_vector(doc.words) for doc in tagged_train_docs]\n",
    "# y_train = [doc.tags for doc in tagged_train_docs]\n",
    "\n",
    "# X_test = [doc_vectorizer.infer_vector(doc.words) for doc in tagged_test_docs]\n",
    "# y_test = [doc.tags for doc in tagged_test_docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파라미터 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.01\n",
    "training_steps = 100000\n",
    "batch_size = 100\n",
    "display_step = 100\n",
    "\n",
    "# Network Parameters\n",
    "num_input = 17 # MNIST data input (img shape: 28*28)\n",
    "timesteps = 2 # timesteps\n",
    "num_hidden = 128 # hidden layer num of features\n",
    "num_classes = 3 # MNIST total classes (0-9 digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터셋 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_np = np.asarray(X_train)\n",
    "# y_train_np = np.asarray([0 if c == 'NEGA' else 1 if c == 'SOSO' else 2 for c in y_train], dtype=int)\n",
    "\n",
    "# X_test_np = np.asarray(X_test)\n",
    "# y_test_np = np.asarray([0 if c == 'NEGA' else 1 if c == 'SOSO' else 2 for c in y_test], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_np = np.eye(3)[y_train_np.reshape(-1)]\n",
    "# y_test_np = np.eye(3)[y_test_np.reshape(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_np[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.contrib import rnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## placeholder 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf Graph input\n",
    "X = tf.placeholder(\"float\", [None, timesteps, num_input])\n",
    "Y = tf.placeholder(\"float\", [None, num_classes])\n",
    "\n",
    "# Define weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.random_normal([num_hidden, num_classes]))\n",
    "}\n",
    "biases = {\n",
    "    'out': tf.Variable(tf.random_normal([num_classes]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RNN(x, weights, biases):\n",
    "\n",
    "    # Prepare data shape to match `rnn` function requirements\n",
    "    # Current data input shape: (batch_size, timesteps, n_input)\n",
    "    # Required shape: 'timesteps' tensors list of shape (batch_size, n_input)\n",
    "\n",
    "    # Unstack to get a list of 'timesteps' tensors of shape (batch_size, n_input)\n",
    "    x = tf.unstack(x, timesteps, 1)\n",
    "\n",
    "    # Define a lstm cell with tensorflow\n",
    "    lstm_cell = rnn.BasicLSTMCell(num_hidden, forget_bias=1.0)\n",
    "\n",
    "    # Get lstm cell output\n",
    "    outputs, states = rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "\n",
    "    # Linear activation, using rnn inner loop last output\n",
    "    return tf.matmul(outputs[-1], weights['out']) + biases['out']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = RNN(X, weights, biases)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "\n",
    "# Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "# Evaluate model (with test logits, for dropout to be disabled)\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Minibatch Loss= 1.6482, Training Accuracy= 0.580\n",
      "Step 100, Minibatch Loss= 0.7930, Training Accuracy= 0.750\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-1219a7dccbea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mbatch_ys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train_np\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mbatch_xs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimesteps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_ys\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdisplay_step\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1276\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1261\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # Run the initializer\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, training_steps+1):\n",
    "        for i in range(0, len(X_train_np), batch_size):\n",
    "            batch_xs = X_train_np[i:i+batch_size]\n",
    "            batch_ys = y_train_np[i:i+batch_size]\n",
    "            batch_xs = batch_xs.reshape((batch_size, timesteps, num_input))\n",
    "            sess.run(train_op, feed_dict={X: batch_xs, Y: batch_ys})\n",
    "        \n",
    "        if step % display_step == 0 or step == 1:\n",
    "            # Calculate batch loss and accuracy\n",
    "            loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_xs,\n",
    "                                                                 Y: batch_ys})\n",
    "            print(\"Step \" + str(step) + \", Minibatch Loss= \" + \\\n",
    "                  \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                  \"{:.3f}\".format(acc))\n",
    "            \n",
    "    print(\"Optimization Finished!\")\n",
    "\n",
    "#     Calculate accuracy for 128 mnist test images\n",
    "    test_len = 128\n",
    "    test_data = X_test_np[:test_len].reshape((-1, timesteps, num_input))\n",
    "    test_label = y_test_np[:test_len]\n",
    "    print(\"Testing Accuracy:\", \\\n",
    "        sess.run(accuracy, feed_dict={X: test_data, Y: test_label}))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
